{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import fcos_resnet50_fpn, FCOS_ResNet50_FPN_Weights\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/fcos_resnet50_fpn_coco-99b0c9b7.pth\" to /Users/kamranzolfonoon/.cache/torch/hub/checkpoints/fcos_resnet50_fpn_coco-99b0c9b7.pth\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "model = torchvision.models.detection.fcos_resnet50_fpn(weights=FCOS_ResNet50_FPN_Weights.DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.3137, 0.2980, 0.3020,  ..., 0.3020, 0.3098, 0.3765],\n",
      "         [0.3137, 0.3098, 0.3098,  ..., 0.2980, 0.3059, 0.3686],\n",
      "         [0.3020, 0.2980, 0.3137,  ..., 0.2863, 0.2824, 0.3412],\n",
      "         ...,\n",
      "         [0.1255, 0.1294, 0.1490,  ..., 0.2471, 0.2471, 0.2471],\n",
      "         [0.1176, 0.1451, 0.1373,  ..., 0.2510, 0.2471, 0.2510],\n",
      "         [0.1412, 0.1412, 0.1451,  ..., 0.2667, 0.2627, 0.2588]],\n",
      "\n",
      "        [[0.2902, 0.2745, 0.2667,  ..., 0.2824, 0.2902, 0.3569],\n",
      "         [0.2902, 0.2745, 0.2745,  ..., 0.2784, 0.2863, 0.3490],\n",
      "         [0.2627, 0.2549, 0.2588,  ..., 0.2667, 0.2627, 0.3216],\n",
      "         ...,\n",
      "         [0.1333, 0.1373, 0.1490,  ..., 0.1608, 0.1608, 0.1608],\n",
      "         [0.1255, 0.1451, 0.1373,  ..., 0.1647, 0.1608, 0.1647],\n",
      "         [0.1373, 0.1373, 0.1333,  ..., 0.1804, 0.1765, 0.1725]],\n",
      "\n",
      "        [[0.1569, 0.1412, 0.1451,  ..., 0.1333, 0.1412, 0.2000],\n",
      "         [0.1569, 0.1451, 0.1529,  ..., 0.1294, 0.1373, 0.1922],\n",
      "         [0.1255, 0.1294, 0.1451,  ..., 0.1176, 0.1137, 0.1647],\n",
      "         ...,\n",
      "         [0.0471, 0.0510, 0.0549,  ..., 0.1098, 0.1176, 0.1176],\n",
      "         [0.0392, 0.0510, 0.0431,  ..., 0.1137, 0.1176, 0.1216],\n",
      "         [0.0667, 0.0588, 0.0588,  ..., 0.1294, 0.1255, 0.1216]]])\n",
      "torch.Size([3, 1489, 1831])\n"
     ]
    }
   ],
   "source": [
    "image = Image.open('eagle_images/eagle_in_nest.jpg').convert('RGB')\n",
    "transform = FCOS_ResNet50_FPN_Weights.COCO_V1.transforms()\n",
    "\n",
    "img_tensor = transform(image)\n",
    "print(img_tensor)\n",
    "print(img_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'boxes': tensor([[ 563.6812,  503.9496, 1084.7826,  864.9644],\n",
      "        [ 169.3170,  484.3844, 1095.6603,  864.1298],\n",
      "        [   0.0000,  379.9100, 1039.8561,  916.6207],\n",
      "        [  50.7538,  157.0287, 1113.7601,  838.1597]],\n",
      "       grad_fn=<StackBackward0>), 'scores': tensor([0.7493, 0.4647, 0.2537, 0.2331], grad_fn=<IndexBackward0>), 'labels': tensor([16, 16, 16, 16])}]\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "predictions = model([img_tensor])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_tensor_boxes=draw_bounding_boxes(img_tensor.to(torch.uint8), predictions[0]['boxes'].to(torch.uint8), width=3, colors=(255,255,0))\n",
    "image_boxes = torchvision.transforms.ToPILImage()(img_tensor_boxes)\n",
    "image_boxes.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "827ad0588f2b9223c03ec3ff0b54d57105849ec0fc3cdd736e5228dae4e5b259"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('EaglesCNN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
